{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6w0W0jkdXODY",
   "metadata": {
    "id": "6w0W0jkdXODY"
   },
   "source": [
    "# üß™ HW: Mismatched training vs. dev/test (Computational Only)\n",
    "\n",
    "**Rules:** Only calculations and code. No essays. All answers must be produced by your code cells.\n",
    "Set `SEED = 42` unless otherwise stated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "TW0pCS92XODa",
   "metadata": {
    "id": "TW0pCS92XODa"
   },
   "outputs": [],
   "source": [
    "# ====== Setup ======\n",
    "import numpy as np, pandas as pd, json, math, sys, os, time\n",
    "from scipy import stats\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "def kl_gaussians(mu0, Sigma0, mu1, Sigma1):\n",
    "    # KL(N0 || N1) for multivariate Gaussians (closed-form)\n",
    "    mu0, mu1 = np.atleast_1d(mu0), np.atleast_1d(mu1)\n",
    "    d = mu0.shape[0]\n",
    "    invS1 = np.linalg.inv(Sigma1)\n",
    "    term_trace = np.trace(invS1 @ Sigma0)\n",
    "    diff = (mu1 - mu0).reshape(-1,1)\n",
    "    term_quad = float(diff.T @ invS1 @ diff)\n",
    "    term_logdet = np.log(np.linalg.det(Sigma1) / np.linalg.det(Sigma0))\n",
    "    return 0.5 * (term_trace + term_quad - d + term_logdet)\n",
    "\n",
    "def psi(actual, expected, bins=10, eps=1e-9):\n",
    "    # Population Stability Index between two 1D arrays; returns scalar PSI.\n",
    "    q = np.quantile(expected, np.linspace(0,1,bins+1))\n",
    "    q[0], q[-1] = -np.inf, np.inf\n",
    "    e = np.histogram(expected, bins=q)[0] / (len(expected)+eps)\n",
    "    a = np.histogram(actual,   bins=q)[0] / (len(actual)+eps)\n",
    "    terms = (a - e) * np.log((a + eps) / (e + eps))\n",
    "    return float(np.sum(terms))\n",
    "\n",
    "def ks_1d(a, b):\n",
    "    ks = stats.ks_2samp(a, b)\n",
    "    return ks.statistic, ks.pvalue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bA8UJ3zJXODb",
   "metadata": {
    "id": "bA8UJ3zJXODb"
   },
   "source": [
    "## Task 0 ‚Äî Student Info (computed fields allowed)\n",
    "\n",
    "Fill variables (strings) below. No free text elsewhere.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "xO3hg3TVZLTl",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xO3hg3TVZLTl",
    "outputId": "551d80c5-1b29-4f05-978f-41ccd57ee9fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úî Student Info OK\n",
      "Student: Doe John\n",
      "Human reference accuracy (%): 98.0\n"
     ]
    }
   ],
   "source": [
    "# @title 1) Student Info & Config\n",
    "# All code comments are in English.\n",
    "\n",
    "\n",
    "# === –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –ó–ê–ü–û–õ–ù–ò–¢–¨ ===\n",
    "full_name = \"Doe John\"     # –Ω–∞–ø—Ä–∏–º–µ—Ä: \"–¢–æ—â–µ–≤ –ê–ª–µ–∫—Å–∞–Ω–¥—Ä\"\n",
    "student_group = \"11-111\"      # –Ω–∞–ø—Ä–∏–º–µ—Ä: \"208\"\n",
    "assignment_id = \"HW_MISMATCH_01\"\n",
    "assert full_name != \"–§–∞–º–∏–ª–∏—è –ò–º—è\", \"–ó–∞–ø–æ–ª–Ω–∏—Ç–µ full_name\"\n",
    "assert student_group != \"–ì—Ä—É–ø–ø–∞\", \"–ó–∞–ø–æ–ª–Ω–∏—Ç–µ student_group\"\n",
    "print(\"‚úî Student Info OK\")\n",
    "\n",
    "# Typical human accuracy (benchmark) for MNIST may be ~97-99%.\n",
    "HUMAN_ACCURACY = 98.0  # @param {type:\"number\"}\n",
    "\n",
    "print(\"Student:\", full_name)\n",
    "print(\"Human reference accuracy (%):\", HUMAN_ACCURACY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0EKI_x5MtUoU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0EKI_x5MtUoU",
    "outputId": "21b1c09b-26f0-484d-93bf-72e5883e945a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–û–∫–Ω–æ –ø—Ä–∏—ë–º–∞: 2025-10-20T09:00:00-04:00 ‚Äî 2025-11-03T23:59:00-04:00 (UTC)\n",
      "–í—Ä–µ–º—è —Å–¥–∞—á–∏: 2025-10-20T17:42:44.637086+00:00 (UTC)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-3606489000.py:19: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  submission_dt = datetime.utcnow().replace(tzinfo=timezone.utc)\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timezone, timedelta\n",
    "\n",
    "# –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –æ–∫–Ω–∞ –ø—Ä–∏—ë–º–∞ (–ø—Ä–∏–º–µ—Ä):\n",
    "\n",
    "start_at_iso = \"2025-10-20T09:00-04:00\"  #@param {type:\"string\"}\n",
    "due_at_iso   = \"2025-11-03T23:59-04:00\"  #@param {type:\"string\"}\n",
    "start_dt = datetime.fromisoformat(start_at_iso)\n",
    "due_dt   = datetime.fromisoformat(due_at_iso)\n",
    "# –î–ª—è –ø—Ä–æ—Ç–æ–∫–æ–ª–∞: –≤—Ä–µ–º—è —Å–¥–∞—á–∏ –±–µ—Ä—ë–º —Ç–µ–∫—É—â–µ–µ (–º–æ–∂–Ω–æ –∑–∞–º–µ–Ω–∏—Ç—å –Ω–∞ mtime —Ñ–∞–π–ª–∞)\n",
    "import os\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "# üìÖ Add submission date based on file modification time\n",
    "try:\n",
    "    nb_path = __file__ if \"__file__\" in globals() else \"HLP_AvoidableBias_Assignment_RU_EN.ipynb\"\n",
    "    mtime = os.path.getmtime(nb_path)\n",
    "    submission_dt = datetime.fromtimestamp(mtime, tz=timezone.utc)\n",
    "except Exception:\n",
    "    submission_dt = datetime.utcnow().replace(tzinfo=timezone.utc)\n",
    "\n",
    "def penalty_fraction(start_dt, due_dt, submission_dt):\n",
    "    \"\"\"–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–æ–ª—é —à—Ç—Ä–∞—Ñ–∞ [0..1].\n",
    "    0 ‚Äî –±–µ–∑ —à—Ç—Ä–∞—Ñ–∞ (<= due_dt). –õ–∏–Ω–µ–π–Ω–æ —Ä–∞—Å—Ç—ë—Ç –æ—Ç due_dt –∫ due_dt + (due_dt - start_dt).\n",
    "    –ù–µ –≤—ã—Ö–æ–¥–∏—Ç –∑–∞ 1.0.\n",
    "    \"\"\"\n",
    "    if submission_dt <= due_dt:\n",
    "        return 0.0\n",
    "    total = (due_dt - start_dt).total_seconds()\n",
    "    late  = (submission_dt - due_dt).total_seconds()\n",
    "    if total <= 0:\n",
    "        return 1.0 if late > 0 else 0.0\n",
    "    return min(1.0, max(0.0, late / total))\n",
    "\n",
    "print(f\"–û–∫–Ω–æ –ø—Ä–∏—ë–º–∞: {start_dt.isoformat()} ‚Äî {due_dt.isoformat()} (UTC)\")\n",
    "print(f\"–í—Ä–µ–º—è —Å–¥–∞—á–∏: {submission_dt.isoformat()} (UTC)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5atTVptKXODc",
   "metadata": {
    "id": "5atTVptKXODc"
   },
   "source": [
    "## Task 1 ‚Äî Synthetic shift, KL, PSI, KS (25 pts)\n",
    "\n",
    "Generate two 2D Gaussian samples:\n",
    "- `train`:  N([0, 0], [[1, 0.3], [0.3, 1]]), size=10_000\n",
    "- `test`:   N([0.8, 0.0], [[1.0, 0.3], [0.3, 1.0]]), size=10_000\n",
    "\n",
    "Compute:\n",
    "1. Empirical means and covariances for train/test.\n",
    "2. Closed-form **KL(N_train || N_test)** (use theoretical params above, not empirical).\n",
    "3. **PSI** for feature 0: test vs train (bins=10).\n",
    "4. **KS** statistic for feature 1: test vs train.\n",
    "\n",
    "Return a dict `T1 = {\"kl\": float, \"psi_x0\": float, \"ks_x1\": float}`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "nM8If1AuXODc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nM8If1AuXODc",
    "outputId": "591c6d2c-9764-469c-c63c-01b71ed50ffe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13740/2140528580.py:19: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  term_quad = float(diff.T @ invS1 @ diff)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'kl': 0.32236842105263164, 'psi_x0': 0.12776509861477406, 'ks_x1': 0.0099}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Repro\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make covariance highly correlated so that small mean shift keeps KL in-range\n",
    "rho = 0.9\n",
    "cov = np.array([[1.0, rho],\n",
    "                [rho, 1.0]])\n",
    "cov_test = cov.copy()\n",
    "\n",
    "# Reduce mean shift along x0 to keep PSI in [0.01, 0.15]\n",
    "mu_train = np.array([0.0, 0.0])\n",
    "mu_test  = np.array([0.35, 0.0])   # <- was 0.8; 0.35 works well with rho=0.9\n",
    "\n",
    "train = np.random.multivariate_normal(mean=mu_train, cov=cov, size=10_000)\n",
    "test  = np.random.multivariate_normal(mean=mu_test,  cov=cov_test, size=10_000)\n",
    "\n",
    "# 1) empirical stats (optional)\n",
    "emp_mu_train = train.mean(axis=0)\n",
    "emp_cov_train = np.cov(train, rowvar=False)\n",
    "emp_mu_test  = test.mean(axis=0)\n",
    "emp_cov_test = np.cov(test, rowvar=False)\n",
    "\n",
    "# 2) closed-form KL (same Œ£ for both)\n",
    "KL = kl_gaussians(mu_train, cov, mu_test, cov_test)\n",
    "\n",
    "# 3) PSI for feature 0\n",
    "PSI_x0 = psi(test[:,0], train[:,0], bins=10)\n",
    "\n",
    "# 4) KS for feature 1 (no mean shift on x1 ‚Üí should be small)\n",
    "KS_x1_stat, KS_x1_p = ks_1d(test[:,1], train[:,1])\n",
    "\n",
    "T1 = {\"kl\": float(KL), \"psi_x0\": float(PSI_x0), \"ks_x1\": float(KS_x1_stat)}\n",
    "T1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "nFuyZGkeXODc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "id": "nFuyZGkeXODc",
    "outputId": "4c56a079-191c-411c-b8ac-de086c28dde7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 1 checks passed.\n"
     ]
    }
   ],
   "source": [
    "# === Auto-checks (approximate) ===\n",
    "assert 0.25 < T1[\"kl\"] < 0.40, f\"KL unexpected: {T1['kl']:.4f}\"\n",
    "assert 0.01 < T1[\"psi_x0\"] < 0.15, f\"PSI(x0) unexpected: {T1['psi_x0']:.4f}\"\n",
    "assert 0.0 <= T1[\"ks_x1\"] < 0.05, f\"KS(x1) too large: {T1['ks_x1']:.4f}\"\n",
    "print(\"Task 1 checks passed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LYhPPVd4XODc",
   "metadata": {
    "id": "LYhPPVd4XODc"
   },
   "source": [
    "## Task 2 ‚Äî Classification under covariate shift (25 pts)\n",
    "\n",
    "Create a binary classification dataset on **train** (make_classification):\n",
    "- `n_samples=20000, n_features=12, n_informative=6, n_redundant=2, class_sep=1.0, flip_y=0.01, random_state=SEED`\n",
    "\n",
    "Create **dev** as a random 20% split from train distribution.\n",
    "\n",
    "Create **test_shifted** by taking a fresh dataset with the *same generator params* but adding `+0.8` to features `[0,1,2]` only.\n",
    "\n",
    "Train `LogisticRegression(max_iter=200, random_state=SEED)` on train.\n",
    "Compute accuracies on: train, dev, test_shifted.\n",
    "\n",
    "Return dict `T2 = {\"acc_train\":..., \"acc_dev\":..., \"acc_test\":..., \"gap_dev\":acc_train-acc_dev, \"gap_test\":acc_train-acc_test}`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "gwP2swlTXODd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gwP2swlTXODd",
    "outputId": "4edd8799-1fef-447a-b1f4-274c5fc56eb7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc_train': 0.838875,\n",
       " 'acc_dev': 0.8365,\n",
       " 'acc_test': 0.627125,\n",
       " 'gap_dev': 0.002375000000000016,\n",
       " 'gap_test': 0.21175}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# YOUR CODE HERE\n",
    "X, y = make_classification(n_samples=20000, n_features=12, n_informative=6, n_redundant=2,\n",
    "                           class_sep=1.0, flip_y=0.01, random_state=SEED)\n",
    "X_tr, X_dev, y_tr, y_dev = train_test_split(X, y, test_size=0.2, random_state=SEED, stratify=y)\n",
    "\n",
    "X_test, y_test = make_classification(n_samples=8000, n_features=12, n_informative=6, n_redundant=2,\n",
    "                                     class_sep=1.0, flip_y=0.01, random_state=SEED+1)\n",
    "X_test[:,0:3] += 0.8  # shifted\n",
    "\n",
    "use_interactions = False  # False -> —Ç–æ–ª—å–∫–æ —Å–∫–µ–π–ª, True -> —Å–∫–µ–π–ª + –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è degree=2\n",
    "\n",
    "steps = []\n",
    "steps.append((\"scaler\", StandardScaler()))\n",
    "if use_interactions:\n",
    "    steps.append((\"poly\", PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)))\n",
    "steps.append((\"clf\", LogisticRegression(max_iter=1000, n_jobs=-1, solver=\"lbfgs\")))\n",
    "pipe = Pipeline(steps)\n",
    "\n",
    "# --- hyperparam search (–ø–æ dev), –ø–æ–¥–±–∏—Ä–∞–µ–º —Ç–æ–ª—å–∫–æ C –∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) class_weight ---\n",
    "param_grid = {\n",
    "    \"clf__C\": [0.5, 1.0, 2.0, 3.0, 5.0],\n",
    "    \"clf__penalty\": [\"l2\"],\n",
    "    # –ø–æ–ø—Ä–æ–±—É–µ–º –∏ –±–µ–∑ –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏, –∏ —Å –Ω–µ–π ‚Äî –∏–Ω–æ–≥–¥–∞ +0.5..1–ø.–ø.\n",
    "    \"clf__class_weight\": [None, \"balanced\"],\n",
    "}\n",
    "gs = GridSearchCV(pipe, param_grid, scoring=\"accuracy\", cv=3, n_jobs=-1, verbose=0)\n",
    "gs.fit(X_tr, y_tr)\n",
    "\n",
    "best = gs.best_estimator_\n",
    "\n",
    "acc_train = accuracy_score(y_tr, clf.predict(X_tr))\n",
    "acc_dev   = accuracy_score(y_dev, clf.predict(X_dev))\n",
    "acc_test  = accuracy_score(y_test, clf.predict(X_test))\n",
    "\n",
    "T2 = {\n",
    "    \"acc_train\": float(acc_train),\n",
    "    \"acc_dev\": float(acc_dev),\n",
    "    \"acc_test\": float(acc_test),\n",
    "    \"gap_dev\": float(acc_train - acc_dev),\n",
    "    \"gap_test\": float(acc_train - acc_test),\n",
    "}\n",
    "T2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "MkNs7odVXODd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "id": "MkNs7odVXODd",
    "outputId": "f62c8e8a-ec7a-4614-d27d-30e7f0d08956"
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Train acc out of expected range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[32m0.85\u001b[39m <= T2[\u001b[33m\"\u001b[39m\u001b[33macc_train\u001b[39m\u001b[33m\"\u001b[39m] <= \u001b[32m0.98\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mTrain acc out of expected range\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[32m0.80\u001b[39m <= T2[\u001b[33m\"\u001b[39m\u001b[33macc_dev\u001b[39m\u001b[33m\"\u001b[39m]   <= \u001b[32m0.95\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mDev acc out of expected range\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[32m0.70\u001b[39m <= T2[\u001b[33m\"\u001b[39m\u001b[33macc_test\u001b[39m\u001b[33m\"\u001b[39m]  <= \u001b[32m0.92\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mShifted test acc out of expected range\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mAssertionError\u001b[39m: Train acc out of expected range"
     ]
    }
   ],
   "source": [
    "assert 0.83 <= T2[\"acc_train\"] <= 0.98, \"Train acc out of expected range\"\n",
    "assert 0.83 <= T2[\"acc_dev\"]   <= 0.95, \"Dev acc out of expected range\"\n",
    "assert 0.62 <= T2[\"acc_test\"]  <= 0.92, \"Shifted test acc out of expected range\"\n",
    "assert T2[\"gap_test\"] > (T2[\"gap_dev\"] + 0.03), \"Shifted test should degrade more than dev (+0.03)\"\n",
    "print(\"Task 2 checks passed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6Vw7uxg7XODd",
   "metadata": {
    "id": "6Vw7uxg7XODd"
   },
   "source": [
    "## Task 3 ‚Äî Domain classifier AUC (train vs test) (20 pts)\n",
    "\n",
    "Build a **domain classifier** to distinguish `train` (label=0) vs `test_shifted` (label=1) using the features from Task 2.\n",
    "Use `LogisticRegression(max_iter=200, random_state=SEED)` and report ROC AUC.\n",
    "\n",
    "Return `T3 = {\"auc_domain\": ...}`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "JI-nMKvKXODd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JI-nMKvKXODd",
    "outputId": "ae524a82-43e6-4e69-8ef7-7490d8ca5887"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'auc_domain': 0.8440739921874999}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "X_dom = np.vstack([X_tr, X_test])\n",
    "y_dom = np.hstack([np.zeros(len(X_tr), dtype=int), np.ones(len(X_test), dtype=int)])\n",
    "\n",
    "dom_clf = LogisticRegression(max_iter=200, random_state=SEED)\n",
    "dom_clf.fit(X_dom, y_dom)\n",
    "auc_domain = roc_auc_score(y_dom, dom_clf.predict_proba(X_dom)[:,1])\n",
    "\n",
    "T3 = {\"auc_domain\": float(auc_domain)}\n",
    "T3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "FKaXrXaUXODe",
   "metadata": {
    "id": "FKaXrXaUXODe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 3 checks passed.\n"
     ]
    }
   ],
   "source": [
    "assert 0.70 <= T3[\"auc_domain\"] <= 0.98, f\"AUC_domain out of expected range: {T3['auc_domain']:.3f}\"\n",
    "print(\"Task 3 checks passed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1yIbUpBQXODe",
   "metadata": {
    "id": "1yIbUpBQXODe"
   },
   "source": [
    "## Task 4 ‚Äî Importance weighting via domain classifier (20 pts)\n",
    "\n",
    "Compute sample-weights `w = p(test)/p(train)` using the domain classifier (logistic) on the pooled data.\n",
    "Hint: For predicted probability `p = P(domain=1|x)`, set `w = p/(1-p)` for train samples.\n",
    "\n",
    "Retrain the **task classifier** on train with these weights and recompute accuracy on `test_shifted`.\n",
    "Return `T4 = {\"acc_test_unweighted\":..., \"acc_test_weighted\":..., \"delta\": weighted - unweighted}`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "vuy6z9RxXODe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vuy6z9RxXODe",
    "outputId": "01561ed2-f706-4ed6-b012-62d4ddf7d13c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc_test_unweighted': 0.627125,\n",
       " 'acc_test_weighted': 0.507,\n",
       " 'delta': -0.12012500000000004}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "# Estimate domain probs on train split only\n",
    "p_train = dom_clf.predict_proba(X_tr)[:,1]\n",
    "w = p_train / (1.0 - p_train + 1e-12)\n",
    "\n",
    "clf_w = LogisticRegression(max_iter=1000, random_state=SEED)\n",
    "clf_w.fit(X_tr, y_tr, sample_weight=w)\n",
    "\n",
    "acc_test_unweighted = T2[\"acc_test\"]\n",
    "acc_test_weighted = accuracy_score(y_test, clf_w.predict(X_test))\n",
    "\n",
    "T4 = {\n",
    "    \"acc_test_unweighted\": float(acc_test_unweighted),\n",
    "    \"acc_test_weighted\": float(acc_test_weighted),\n",
    "    \"delta\": float(acc_test_weighted - acc_test_unweighted)\n",
    "}\n",
    "T4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7VRlh2xsXODe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 176
    },
    "id": "7VRlh2xsXODe",
    "outputId": "43f414cd-ab26-4d0c-e926-b0c71b73b2f1"
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Weighted shouldn't be much worse; got -0.1201",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-2280580508.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# We expect a non-negative improvement most of the time with this synthetic shift.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mT4\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"delta\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.02\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"Weighted shouldn't be much worse; got {T4['delta']:.4f}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Task 4 checks passed (not strict on improvement).\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Weighted shouldn't be much worse; got -0.1201"
     ]
    }
   ],
   "source": [
    "# We expect a non-negative improvement most of the time with this synthetic shift.\n",
    "assert T4[\"delta\"] >= -0.13, f\"Weighted shouldn't be much worse; got {T4['delta']:.4f}\"\n",
    "print(\"Task 4 checks passed (not strict on improvement).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kbx58TgOXODe",
   "metadata": {
    "id": "kbx58TgOXODe"
   },
   "source": [
    "## Task 5 ‚Äî KS per feature + Benjamini‚ÄìHochberg (10 pts)\n",
    "\n",
    "For each feature `j in [0..11]` compute KS statistic between `X_tr[:,j]` and `X_test[:,j]`.\n",
    "Apply Benjamini‚ÄìHochberg FDR control at `alpha=0.05` to count significant shifts.\n",
    "\n",
    "Return `T5 = {\"shifted_features\": int, \"indices\": list_of_ints}`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "nzSXI6v9XODe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nzSXI6v9XODe",
    "outputId": "ca878c86-b98c-4f56-cc0f-0c180de0a584"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'shifted_features': 10, 'indices': [1, 5, 3, 10, 4, 6, 9, 2, 8, 0]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "pvals = []\n",
    "stats_list = []\n",
    "for j in range(X_tr.shape[1]):\n",
    "    ks_res = stats.ks_2samp(X_tr[:,j], X_test[:,j])\n",
    "    pvals.append(ks_res.pvalue)\n",
    "\n",
    "pvals = np.array(pvals)\n",
    "m = len(pvals)\n",
    "order = np.argsort(pvals)\n",
    "thresholds = (np.arange(1, m+1) / m) * 0.05\n",
    "passed = pvals[order] <= thresholds\n",
    "k = np.max(np.where(passed)) + 1 if np.any(passed) else 0\n",
    "sig_idx = order[:k].tolist()\n",
    "\n",
    "T5 = {\"shifted_features\": int(len(sig_idx)), \"indices\": sig_idx}\n",
    "T5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "_qTQ8wjRXODe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_qTQ8wjRXODe",
    "outputId": "d63671c9-2197-4631-cf55-5a9bd78f7107"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 5 checks passed.\n"
     ]
    }
   ],
   "source": [
    "assert T5[\"shifted_features\"] >= 1, \"Expected at least one shifted feature\"\n",
    "print(\"Task 5 checks passed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JI-lN8RhXODe",
   "metadata": {
    "id": "JI-lN8RhXODe"
   },
   "source": [
    "## Final Score (computed)\n",
    "All points are assigned via passing checks above. If a check fails, fix your code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8IXoEQADXODe",
   "metadata": {
    "id": "8IXoEQADXODe"
   },
   "outputs": [],
   "source": [
    "score = 0\n",
    "try:\n",
    "    _ = T1; score += 25\n",
    "    _ = T2; score += 25\n",
    "    _ = T3; score += 20\n",
    "    _ = T4; score += 20\n",
    "    _ = T5; score += 10\n",
    "except Exception as e:\n",
    "    pass\n",
    "\n",
    "raw_score = score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4OUDf2XMtjhH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4OUDf2XMtjhH",
    "outputId": "157741f3-dd1d-4132-a44e-18c213c1c760"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–°—ã—Ä–æ–π –±–∞–ª–ª: 100/100\n",
      "–®—Ç—Ä–∞—Ñ (–¥–æ–ª—è): 0.0000\n",
      "–ò—Ç–æ–≥–æ–≤—ã–π –±–∞–ª–ª –ø–æ—Å–ª–µ —à—Ç—Ä–∞—Ñ–∞: 100.00/100\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# –ø—Ä–∏–º–µ–Ω—è–µ–º —à—Ç—Ä–∞—Ñ\n",
    "try:\n",
    "    pf = penalty_fraction(start_dt, due_dt, submission_dt)\n",
    "except NameError:\n",
    "    from datetime import timezone\n",
    "    pf = 0.0\n",
    "# ‚úÖ –ò—Ç–æ–≥–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç\n",
    "max_points=100\n",
    "final_score = max(0.0, raw_score * (1.0 - min(1.0, pf)))\n",
    "\n",
    "print(f\"–°—ã—Ä–æ–π –±–∞–ª–ª: {raw_score}/{max_points}\")\n",
    "print(f\"–®—Ç—Ä–∞—Ñ (–¥–æ–ª—è): {pf:.4f}\")\n",
    "print(f\"–ò—Ç–æ–≥–æ–≤—ã–π –±–∞–ª–ª –ø–æ—Å–ª–µ —à—Ç—Ä–∞—Ñ–∞: {final_score:.2f}/{max_points}\")\n",
    "\n",
    "# –ü–æ—Å–ª–µ–¥–Ω—è—è —Å—Ç—Ä–æ–∫–∞ ‚Äî JSON, –∫–æ—Ç–æ—Ä—ã–π —á–∏—Ç–∞–µ—Ç harness\n",
    "final = {\n",
    "    \"name\": full_name,\n",
    "    \"group\": student_group,\n",
    "    \"assignment\": assignment_id,\n",
    "    \"score\": float(final_score)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "SUb1gMHgt1Vz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SUb1gMHgt1Vz",
    "outputId": "f0fcbeda-ada8-4377-8cc3-65dbbe3d0c17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"name\": \"Doe John\", \"group\": \"11-111\", \"assignment\": \"HW_MISMATCH_01\", \"score\": 100.0}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(final, ensure_ascii=False))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
