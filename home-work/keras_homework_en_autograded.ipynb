{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexander-toschev/ml-cs-intro/blob/main/home-work/keras_homework_en_autograded.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gqg72kzIOf3f"
      },
      "source": [
        "# Homework: Introduction to Keras (with simple autograder)\n",
        "\n",
        "In this homework you will work with `tf.keras` on the MNIST dataset.\n",
        "\n",
        "Goals:\n",
        "- recall the basic training pipeline for a neural network;\n",
        "- build a simple Keras model (MLP and CNN);\n",
        "- practice using callbacks and regularization;\n",
        "- compare the performance of different architectures.\n",
        "\n",
        "Each task has an assigned number of points.\n",
        "\n",
        "**Maximum score: 100 points**  \n",
        "Task 1 ‚Äî 10 pts  \n",
        "Task 2 ‚Äî 20 pts  \n",
        "Task 3 ‚Äî 20 pts  \n",
        "Task 4 ‚Äî 20 pts  \n",
        "Task 5 ‚Äî 30 pts\n",
        "\n",
        "Below is a **very simple autograder**:\n",
        "- After each task there is a test cell.\n",
        "- If tests pass, points for that task are added to the total.\n",
        "- If tests fail or raise an error, the task gives 0 points.\n"
      ],
      "id": "Gqg72kzIOf3f"
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 1) Student Info & Config\n",
        "# All code comments are in English.\n",
        "\n",
        "\n",
        "# === –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –ó–ê–ü–û–õ–ù–ò–¢–¨ ===\n",
        "full_name = \"Doe John\"     # –Ω–∞–ø—Ä–∏–º–µ—Ä: \"–¢–æ—â–µ–≤ –ê–ª–µ–∫—Å–∞–Ω–¥—Ä\"\n",
        "student_group = \"11-111\"      # –Ω–∞–ø—Ä–∏–º–µ—Ä: \"208\"\n",
        "assignment_id = \"EM02_Keras\"\n",
        "assert full_name != \"–§–∞–º–∏–ª–∏—è –ò–º—è\", \"–ó–∞–ø–æ–ª–Ω–∏—Ç–µ full_name\"\n",
        "assert student_group != \"–ì—Ä—É–ø–ø–∞\", \"–ó–∞–ø–æ–ª–Ω–∏—Ç–µ student_group\"\n",
        "print(\"‚úî Student Info OK\")\n",
        "\n",
        "# Typical human accuracy (benchmark) for MNIST may be ~97-99%.\n",
        "\n",
        "print(\"Student:\", full_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QGZCdwfOplg",
        "outputId": "90bfd734-b53b-4190-cec2-a7964647eb2a"
      },
      "id": "-QGZCdwfOplg",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úî Student Info OK\n",
            "Student: Doe John\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def _close(a, b, tol=1e-8):\n",
        "    return np.allclose(a, b, atol=tol)\n",
        "\n",
        "def _arr_equal(a, b):\n",
        "    a = np.array(a)\n",
        "    b = np.array(b)\n",
        "    return a.shape == b.shape and np.array_equal(a, b)"
      ],
      "metadata": {
        "id": "H1MGC-B8OrzJ"
      },
      "id": "H1MGC-B8OrzJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime, timezone, timedelta\n",
        "\n",
        "# –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –æ–∫–Ω–∞ –ø—Ä–∏—ë–º–∞ (–ø—Ä–∏–º–µ—Ä):\n",
        "\n",
        "start_at_iso = \"2025-12-01T09:00-04:00\"  #@param {type:\"string\"}\n",
        "due_at_iso   = \"2025-12-08T23:59-04:00\"  #@param {type:\"string\"}\n",
        "start_dt = datetime.fromisoformat(start_at_iso)\n",
        "due_dt   = datetime.fromisoformat(due_at_iso)\n",
        "# –î–ª—è –ø—Ä–æ—Ç–æ–∫–æ–ª–∞: –≤—Ä–µ–º—è —Å–¥–∞—á–∏ –±–µ—Ä—ë–º —Ç–µ–∫—É—â–µ–µ (–º–æ–∂–Ω–æ –∑–∞–º–µ–Ω–∏—Ç—å –Ω–∞ mtime —Ñ–∞–π–ª–∞)\n",
        "import os\n",
        "from datetime import datetime, timezone\n",
        "\n",
        "# üìÖ Add submission date based on file modification time\n",
        "try:\n",
        "    nb_path = __file__ if \"__file__\" in globals() else \"EM01_Numpy.ipynb\"\n",
        "    mtime = os.path.getmtime(nb_path)\n",
        "    submission_dt = datetime.fromtimestamp(mtime, tz=timezone.utc)\n",
        "except Exception:\n",
        "    submission_dt = datetime.utcnow().replace(tzinfo=timezone.utc)\n",
        "\n",
        "def penalty_fraction(start_dt, due_dt, submission_dt):\n",
        "    \"\"\"–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–æ–ª—é —à—Ç—Ä–∞—Ñ–∞ [0..1].\n",
        "    0 ‚Äî –±–µ–∑ —à—Ç—Ä–∞—Ñ–∞ (<= due_dt). –õ–∏–Ω–µ–π–Ω–æ —Ä–∞—Å—Ç—ë—Ç –æ—Ç due_dt –∫ due_dt + (due_dt - start_dt).\n",
        "    –ù–µ –≤—ã—Ö–æ–¥–∏—Ç –∑–∞ 1.0.\n",
        "    \"\"\"\n",
        "    if submission_dt <= due_dt:\n",
        "        return 0.0\n",
        "    total = (due_dt - start_dt).total_seconds()\n",
        "    late  = (submission_dt - due_dt).total_seconds()\n",
        "    if total <= 0:\n",
        "        return 1.0 if late > 0 else 0.0\n",
        "    return min(1.0, max(0.0, late / total))\n",
        "\n",
        "print(f\"–û–∫–Ω–æ –ø—Ä–∏—ë–º–∞: {start_dt.isoformat()} ‚Äî {due_dt.isoformat()} (UTC)\")\n",
        "print(f\"–í—Ä–µ–º—è —Å–¥–∞—á–∏: {submission_dt.isoformat()} (UTC)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upeE8xafOxil",
        "outputId": "fca9e98c-41e0-40fa-b815-350c31020d4d"
      },
      "id": "upeE8xafOxil",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "–û–∫–Ω–æ –ø—Ä–∏—ë–º–∞: 2025-11-24T09:00:00-04:00 ‚Äî 2025-12-01T23:59:00-04:00 (UTC)\n",
            "–í—Ä–µ–º—è —Å–¥–∞—á–∏: 2025-12-01T14:07:03.072575+00:00 (UTC)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-632059888.py:19: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  submission_dt = datetime.utcnow().replace(tzinfo=timezone.utc)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Kca4rhIOf3h"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# === Grading setup ===\n",
        "\n",
        "max_points = {\n",
        "    \"task1\": 10,\n",
        "    \"task2\": 20,\n",
        "    \"task3\": 20,\n",
        "    \"task4\": 20,\n",
        "    \"task5\": 30,\n",
        "}\n",
        "\n",
        "total_points = 0\n",
        "\n",
        "def add_points(task_name, ok):\n",
        "    \"\"\"Add points for a task if ok == True, print running total.\"\"\"\n",
        "    global total_points\n",
        "    max_total = sum(max_points.values())\n",
        "    if ok:\n",
        "        pts = max_points[task_name]\n",
        "        total_points += pts\n",
        "        print(f\"{task_name}: +{pts} points ‚úÖ (total = {total_points}/{max_total})\")\n",
        "    else:\n",
        "        print(f\"{task_name}: 0 points ‚ùå (total = {total_points}/{max_total})\")\n"
      ],
      "id": "_Kca4rhIOf3h"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sU34YOyKOf3i",
        "outputId": "35db1e11-423f-486f-caf3-79620c2e9608"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.19.0\n"
          ]
        }
      ],
      "source": [
        "# If needed, uncomment the line below to install/upgrade TensorFlow\n",
        "# !pip install -q \"tensorflow>=2.15\"\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"TensorFlow version:\", tf.__version__)\n"
      ],
      "id": "sU34YOyKOf3i"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPmHRB7mOf3j"
      },
      "source": [
        "## Task 1 (10 points)\n",
        "### Loading and preprocessing data\n",
        "\n",
        "Load the MNIST dataset using `keras.datasets.mnist.load_data()` and prepare the data:\n",
        "- cast to `float32`;\n",
        "- normalize pixel values to `[0, 1]` (divide by 255);\n",
        "- print shapes of train and test arrays.\n",
        "\n",
        "**Required:** implement `load_mnist()` that returns a tuple `(x_train, y_train, x_test, y_test)` with **normalized** data.\n"
      ],
      "id": "TPmHRB7mOf3j"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNl62vRGOf3j"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "def load_mnist():\n",
        "    \"\"\"Load and normalize MNIST.\n",
        "    Returns: x_train, y_train, x_test, y_test.\n",
        "    \"\"\"\n",
        "    # TODO: your code here\n",
        "    # 1) load data\n",
        "    # 2) cast to float32\n",
        "    # 3) divide by 255\n",
        "    raise NotImplementedError\n"
      ],
      "id": "mNl62vRGOf3j"
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "autograder"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqWL_8WeOf3j",
        "outputId": "d689fb2a-77cb-4e7f-9369-8981c581e85a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task 1 error: \n",
            "task1: 0 points ‚ùå (total = 0/100)\n"
          ]
        }
      ],
      "source": [
        "# === Autograder: Task 1 ===\n",
        "try:\n",
        "    x_train, y_train, x_test, y_test = load_mnist()\n",
        "    cond_dtype = (x_train.dtype == np.float32 and x_test.dtype == np.float32)\n",
        "    cond_range = (\n",
        "        x_train.min() >= -1e-6 and x_train.max() <= 1.0 + 1e-6 and\n",
        "        x_test.min() >= -1e-6 and x_test.max() <= 1.0 + 1e-6\n",
        "    )\n",
        "    cond_shape = (\n",
        "        x_train.shape[0] == y_train.shape[0] and\n",
        "        x_test.shape[0] == y_test.shape[0]\n",
        "    )\n",
        "    ok = bool(cond_dtype and cond_range and cond_shape)\n",
        "    add_points(\"task1\", ok)\n",
        "except Exception as e:\n",
        "    print(\"Task 1 error:\", e)\n",
        "    add_points(\"task1\", False)\n"
      ],
      "id": "FqWL_8WeOf3j"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDlGkszhOf3j"
      },
      "source": [
        "## Task 2 (20 points)\n",
        "### Basic MLP model in Keras\n",
        "\n",
        "Implement `build_mlp(input_shape, num_classes)` that creates and returns a **compiled** Keras model.\n",
        "\n",
        "Architecture requirements (you may add layers, but do not simplify):\n",
        "- input: `Input(shape=input_shape)`;\n",
        "- `Flatten()` layer;\n",
        "- dense layer with **at least 64 units** and `relu` activation;\n",
        "- `Dropout` layer with rate at least 0.2;\n",
        "- output: Dense with `num_classes` units and `softmax` activation.\n",
        "\n",
        "Compilation requirements:\n",
        "- optimizer: Adam;\n",
        "- loss: `sparse_categorical_crossentropy`;\n",
        "- metric: accuracy.\n"
      ],
      "id": "DDlGkszhOf3j"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mb65cguxOf3j"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "def build_mlp(input_shape, num_classes):\n",
        "    \"\"\"Create and compile a simple MLP model in Keras.\n",
        "\n",
        "    input_shape: tuple, e.g. (28, 28)\n",
        "    num_classes: number of classes (for MNIST ‚Äî 10)\n",
        "    \"\"\"\n",
        "    # TODO: your code here\n",
        "    # 1) build a Sequential model\n",
        "    # 2) add Flatten, Dense, Dropout, Dense\n",
        "    # 3) call compile(...)\n",
        "    raise NotImplementedError\n"
      ],
      "id": "Mb65cguxOf3j"
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "autograder"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzGq68V8Of3j",
        "outputId": "82ff053a-cdce-4000-83fd-77403cc17aaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task 2 error: \n",
            "task2: 0 points ‚ùå (total = 0/100)\n"
          ]
        }
      ],
      "source": [
        "# === Autograder: Task 2 ===\n",
        "try:\n",
        "    model_mlp = build_mlp((28, 28), 10)\n",
        "    compiled = hasattr(model_mlp, \"loss\") and model_mlp.loss is not None\n",
        "    layer_types = [type(l).__name__ for l in model_mlp.layers]\n",
        "    has_flatten = \"Flatten\" in layer_types\n",
        "    has_dropout = \"Dropout\" in layer_types\n",
        "    has_dense = layer_types.count(\"Dense\") >= 2\n",
        "    ok = bool(compiled and has_flatten and has_dropout and has_dense)\n",
        "    add_points(\"task2\", ok)\n",
        "except Exception as e:\n",
        "    print(\"Task 2 error:\", e)\n",
        "    add_points(\"task2\", False)\n"
      ],
      "id": "wzGq68V8Of3j"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAWHevDAOf3k"
      },
      "source": [
        "## Task 3 (20 points)\n",
        "### Training with validation and callbacks\n",
        "\n",
        "Implement `train_model(model, x_train, y_train, x_val, y_val)` that:\n",
        "- takes a **compiled** model;\n",
        "- trains it on `x_train, y_train`;\n",
        "- uses validation data `x_val, y_val`;\n",
        "- returns the `history` object.\n",
        "\n",
        "Requirements:\n",
        "- `batch_size` not larger than 256;\n",
        "- at least 5 epochs of training;\n",
        "- use `EarlyStopping` callback on validation loss with `patience` between 2 and 4 and `restore_best_weights=True`.\n"
      ],
      "id": "TAWHevDAOf3k"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9DbZHQcOf3k"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "def train_model(model, x_train, y_train, x_val, y_val):\n",
        "    \"\"\"Train the model and return history.\n",
        "\n",
        "    Configure EarlyStopping here.\n",
        "    \"\"\"\n",
        "    # TODO: your code here\n",
        "    # 1) create EarlyStopping callback\n",
        "    # 2) call model.fit(...)\n",
        "    raise NotImplementedError\n"
      ],
      "id": "Y9DbZHQcOf3k"
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "autograder"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXxeBlJQOf3k",
        "outputId": "c792911f-86b5-490a-eb2e-c1b241880fce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task 3 error: \n",
            "task3: 0 points ‚ùå (total = 0/100)\n"
          ]
        }
      ],
      "source": [
        "# === Autograder: Task 3 ===\n",
        "try:\n",
        "    x_train, y_train, x_test, y_test = load_mnist()\n",
        "    x_tr, x_val = x_train[:5000], x_train[5000:6000]\n",
        "    y_tr, y_val = y_train[:5000], y_train[5000:6000]\n",
        "\n",
        "    model_mlp = build_mlp((28, 28), 10)\n",
        "    history_mlp = train_model(model_mlp, x_tr, y_tr, x_val, y_val)\n",
        "\n",
        "    h = getattr(history_mlp, \"history\", {})\n",
        "    ok = all(k in h for k in [\"loss\", \"val_loss\", \"accuracy\", \"val_accuracy\"])\n",
        "    add_points(\"task3\", bool(ok))\n",
        "except Exception as e:\n",
        "    print(\"Task 3 error:\", e)\n",
        "    add_points(\"task3\", False)\n"
      ],
      "id": "EXxeBlJQOf3k"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPp34nRCOf3l"
      },
      "source": [
        "## Task 4 (20 points)\n",
        "### Plotting training curves\n",
        "\n",
        "Implement `plot_history(history)` that:\n",
        "- plots loss (train/val) vs epoch;\n",
        "- plots accuracy (train/val) vs epoch.\n",
        "\n",
        "Requirements:\n",
        "- use `matplotlib`;\n",
        "- add legend and axis labels.\n"
      ],
      "id": "KPp34nRCOf3l"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOq0RYwWOf3l"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "def plot_history(history):\n",
        "    \"\"\"Plot training curves from a Keras history object.\"\"\"\n",
        "    # TODO: your code here\n",
        "    # Hint: history.history is a dict with keys 'loss', 'val_loss', 'accuracy', 'val_accuracy'\n",
        "    raise NotImplementedError\n"
      ],
      "id": "BOq0RYwWOf3l"
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "autograder"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1vv2JzfOf3l",
        "outputId": "a92bce0e-a426-44f9-d06a-981aa5d82f57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task 4 error: name 'history_mlp' is not defined\n",
            "task4: 0 points ‚ùå (total = 0/100)\n"
          ]
        }
      ],
      "source": [
        "# === Autograder: Task 4 ===\n",
        "try:\n",
        "    plot_history(history_mlp)\n",
        "    add_points(\"task4\", True)\n",
        "except Exception as e:\n",
        "    print(\"Task 4 error:\", e)\n",
        "    add_points(\"task4\", False)\n"
      ],
      "id": "E1vv2JzfOf3l"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKxpziDqOf3m"
      },
      "source": [
        "## Task 5 (30 points)\n",
        "### CNN for MNIST and comparison with MLP\n",
        "\n",
        "Now you need to:\n",
        "1. Implement `build_cnn(input_shape, num_classes)` that builds a simple **convolutional** model:\n",
        "   - at least two convolutional layers (`Conv2D`) with `relu` activation;\n",
        "   - pooling (e.g. `MaxPooling2D`);\n",
        "   - `Flatten` layer;\n",
        "   - one or two dense layers and final `Dense(num_classes, softmax)`.\n",
        "2. Remember that for a CNN the input shape should be `(H, W, 1)` ‚Äî you need to add a channel dimension.\n",
        "3. Train the CNN on the same data as the MLP (you can reuse `train_model`).\n",
        "4. Compare test accuracy for both models (print both values).\n",
        "\n",
        "**Required:**\n",
        "- implement `build_cnn`;\n",
        "- properly reshape the data;\n",
        "- train the CNN and print final test accuracy.\n"
      ],
      "id": "tKxpziDqOf3m"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyfolM89Of3m"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "def build_cnn(input_shape, num_classes):\n",
        "    \"\"\"Create and compile a simple CNN model for MNIST.\"\"\"\n",
        "    # TODO: your code here\n",
        "    # 1) use Conv2D, MaxPooling2D, Flatten, Dense\n",
        "    # 2) don't forget compile(...)\n",
        "    raise NotImplementedError\n"
      ],
      "id": "YyfolM89Of3m"
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "autograder"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOlozRWcOf3m",
        "outputId": "f801a2c2-403f-4ec9-a14d-c3c00f7051e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task 5 error: \n",
            "task5: 0 points ‚ùå (total = 0/100)\n"
          ]
        }
      ],
      "source": [
        "# === Autograder: Task 5 ===\n",
        "try:\n",
        "    x_train, y_train, x_test, y_test = load_mnist()\n",
        "    x_train_cnn = np.expand_dims(x_train, axis=-1)\n",
        "    x_test_cnn = np.expand_dims(x_test, axis=-1)\n",
        "\n",
        "    x_tr_cnn, x_val_cnn = x_train_cnn[:5000], x_train_cnn[5000:6000]\n",
        "    y_tr_cnn, y_val_cnn = y_train[:5000], y_train[5000:6000]\n",
        "\n",
        "    model_cnn = build_cnn((28, 28, 1), 10)\n",
        "    history_cnn = train_model(model_cnn, x_tr_cnn, y_tr_cnn, x_val_cnn, y_val_cnn)\n",
        "\n",
        "    layer_types = [type(l).__name__ for l in model_cnn.layers]\n",
        "    has_conv = layer_types.count(\"Conv2D\") >= 2\n",
        "    has_pool = \"MaxPooling2D\" in layer_types\n",
        "    ok = bool(has_conv and has_pool)\n",
        "    add_points(\"task5\", ok)\n",
        "except Exception as e:\n",
        "    print(\"Task 5 error:\", e)\n",
        "    add_points(\"task5\", False)\n"
      ],
      "id": "wOlozRWcOf3m"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeWdceb7Of3m"
      },
      "source": [
        "## Final total\n",
        "\n",
        "Run the cell below at the end just to re-print the final score stored in `total_points`.\n"
      ],
      "id": "GeWdceb7Of3m"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7OUvo40Of3m",
        "outputId": "a4dbc32a-6eb6-42ed-e7e9-ea251cb33a85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final score: 0/100\n"
          ]
        }
      ],
      "source": [
        "max_total = sum(max_points.values())\n",
        "print(f\"Final score: {total_points}/{max_total}\")\n"
      ],
      "id": "E7OUvo40Of3m"
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "from datetime import datetime, timezone\n",
        "\n",
        "# ---------- —Ç–µ—Å—Ç–æ–≤—ã–µ –ø–æ–º–æ—â–Ω–∏–∫–∏ ----------\n",
        "def add_points(ok, pts, msg_ok, msg_fail):\n",
        "    global total\n",
        "    if ok:\n",
        "        total += pts\n",
        "        print(f\"[+{pts:>2}] {msg_ok}\")\n",
        "    else:\n",
        "        print(f\"[ 0] {msg_fail}\")\n",
        "\n",
        "def _sec(td):\n",
        "    return td.total_seconds()\n",
        "\n",
        "def penalty_fraction(start_dt, due_dt, now_dt) -> float:\n",
        "    if not (start_dt and due_dt and now_dt):\n",
        "        return 0.0\n",
        "    window = _sec(due_dt - start_dt)\n",
        "    if window <= 0:\n",
        "        return 1.0 if now_dt > due_dt else 0.0\n",
        "    late = max(0.0, _sec(now_dt - due_dt))\n",
        "    return min(1.0, late / window)\n",
        "\n",
        "# ---------- –∞–≤—Ç–æ–≥—Ä–µ–π–¥–∏–Ω–≥ ----------\n",
        "total = total_points\n",
        "max_points = max_total\n",
        "raw_score = total_points\n",
        "\n",
        "import json\n",
        "\n",
        "# –ø—Ä–∏–º–µ–Ω—è–µ–º —à—Ç—Ä–∞—Ñ\n",
        "try:\n",
        "    pf = penalty_fraction(start_dt, due_dt, submission_dt)\n",
        "except NameError:\n",
        "    from datetime import timezone\n",
        "    pf = 0.0\n",
        "# ‚úÖ –ò—Ç–æ–≥–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç\n",
        "\n",
        "max_points = 100\n",
        "\n",
        "raw_score = round(100.0 * total / max_points)\n",
        "final_score = max(0.0, raw_score * (1.0 - min(1.0, pf)))\n",
        "\n",
        "print(f\"–°—ã—Ä–æ–π –±–∞–ª–ª: {raw_score}/{max_points}\")\n",
        "print(f\"–®—Ç—Ä–∞—Ñ (–¥–æ–ª—è): {pf:.4f}\")\n",
        "print(f\"–ò—Ç–æ–≥–æ–≤—ã–π –±–∞–ª–ª –ø–æ—Å–ª–µ —à—Ç—Ä–∞—Ñ–∞: {final_score:.2f}/{max_points}\")\n",
        "\n",
        "# –ü–æ—Å–ª–µ–¥–Ω—è—è —Å—Ç—Ä–æ–∫–∞ ‚Äî JSON, –∫–æ—Ç–æ—Ä—ã–π —á–∏—Ç–∞–µ—Ç harness\n",
        "final = {\n",
        "    \"name\": full_name,\n",
        "    \"group\": student_group,\n",
        "    \"assignment\": assignment_id,\n",
        "    \"score\": float(final_score)\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBpdQG6kO63O",
        "outputId": "9c2899ce-d330-4f05-ecd0-9768d30b90e8"
      },
      "id": "KBpdQG6kO63O",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "–°—ã—Ä–æ–π –±–∞–ª–ª: 0/100\n",
            "–®—Ç—Ä–∞—Ñ (–¥–æ–ª—è): 0.0000\n",
            "–ò—Ç–æ–≥–æ–≤—ã–π –±–∞–ª–ª –ø–æ—Å–ª–µ —à—Ç—Ä–∞—Ñ–∞: 0.00/100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(json.dumps(final, ensure_ascii=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NX5xY9SPD9y",
        "outputId": "9a087a3d-0ef5-4b7a-d7c4-61f6d4ef2428"
      },
      "id": "2NX5xY9SPD9y",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"name\": \"Doe John\", \"group\": \"11-111\", \"assignment\": \"EM01_Numpy\", \"score\": 0.0}\n"
          ]
        }
      ]
    }
  ]
}