{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91313717",
   "metadata": {
    "id": "91313717"
   },
   "source": [
    "# üß™ Transfer Learning Assignment (PyTorch)\n",
    "\n",
    "–ê–≤—Ç–æ–ø—Ä–æ–≤–µ—Ä–∫–∞ –≤–∫–ª—é—á–µ–Ω–∞. –ó–∞–ø–æ–ª–Ω—è–π—Ç–µ –ø–æ–ª—è –≤ —Å–∞–º–æ–º –ø–µ—Ä–≤–æ–º –±–ª–æ–∫–µ.\n",
    "–ì–¥–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è ‚Äî **–Ω–µ –º–µ–Ω—è–π—Ç–µ –∏–º–µ–Ω–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "220cf57c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "220cf57c",
    "outputId": "f81e8052-a6da-4942-9ac0-3385eae474da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úî Student Info OK\n",
      "Student: Doe John\n",
      "Human reference accuracy (%): 98.0\n",
      "–û–∫–Ω–æ –ø—Ä–∏—ë–º–∞: 2025-10-20T09:00:00-04:00 ‚Äî 2025-11-03T23:59:00-04:00 (UTC)\n",
      "–í—Ä–µ–º—è —Å–¥–∞—á–∏: 2025-10-27T10:45:16.230701+00:00 (UTC)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-1206189244.py:36: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  submission_dt = datetime.utcnow().replace(tzinfo=timezone.utc)\n"
     ]
    }
   ],
   "source": [
    "# @title 1) Student Info & Config\n",
    "# All code comments are in English.\n",
    "\n",
    "# === –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –ó–ê–ü–û–õ–ù–ò–¢–¨ ===\n",
    "full_name = \"Doe John\"     # –Ω–∞–ø—Ä–∏–º–µ—Ä: \"–¢–æ—â–µ–≤ –ê–ª–µ–∫—Å–∞–Ω–¥—Ä\"\n",
    "student_group = \"11-111\"      # –Ω–∞–ø—Ä–∏–º–µ—Ä: \"208\"\n",
    "assignment_id = \"HW_MISMATCH_01\"\n",
    "assert full_name != \"–§–∞–º–∏–ª–∏—è –ò–º—è\", \"–ó–∞–ø–æ–ª–Ω–∏—Ç–µ full_name\"\n",
    "assert student_group != \"–ì—Ä—É–ø–ø–∞\", \"–ó–∞–ø–æ–ª–Ω–∏—Ç–µ student_group\"\n",
    "print(\"‚úî Student Info OK\")\n",
    "\n",
    "# Typical human accuracy (benchmark) for MNIST may be ~97-99%.\n",
    "HUMAN_ACCURACY = 98.0  # @param {type:\"number\"}\n",
    "\n",
    "print(\"Student:\", full_name)\n",
    "print(\"Human reference accuracy (%):\", HUMAN_ACCURACY)\n",
    "\n",
    "from datetime import datetime, timezone, timedelta\n",
    "\n",
    "# –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –æ–∫–Ω–∞ –ø—Ä–∏—ë–º–∞ (–ø—Ä–∏–º–µ—Ä):\n",
    "\n",
    "start_at_iso = \"2025-10-20T09:00-04:00\"  #@param {type:\"string\"}\n",
    "due_at_iso   = \"2025-11-03T23:59-04:00\"  #@param {type:\"string\"}\n",
    "start_dt = datetime.fromisoformat(start_at_iso)\n",
    "due_dt   = datetime.fromisoformat(due_at_iso)\n",
    "# –î–ª—è –ø—Ä–æ—Ç–æ–∫–æ–ª–∞: –≤—Ä–µ–º—è —Å–¥–∞—á–∏ –±–µ—Ä—ë–º —Ç–µ–∫—É—â–µ–µ (–º–æ–∂–Ω–æ –∑–∞–º–µ–Ω–∏—Ç—å –Ω–∞ mtime —Ñ–∞–π–ª–∞)\n",
    "import os\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "# üìÖ Add submission date based on file modification time\n",
    "try:\n",
    "    nb_path = __file__ if \"__file__\" in globals() else \"Transfer_Learning_Assignment.ipynb\"\n",
    "    mtime = os.path.getmtime(nb_path)\n",
    "    submission_dt = datetime.fromtimestamp(mtime, tz=timezone.utc)\n",
    "except Exception:\n",
    "    submission_dt = datetime.utcnow().replace(tzinfo=timezone.utc)\n",
    "\n",
    "def penalty_fraction(start_dt, due_dt, submission_dt):\n",
    "    \"\"\"–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–æ–ª—é —à—Ç—Ä–∞—Ñ–∞ [0..1].\n",
    "    0 ‚Äî –±–µ–∑ —à—Ç—Ä–∞—Ñ–∞ (<= due_dt). –õ–∏–Ω–µ–π–Ω–æ —Ä–∞—Å—Ç—ë—Ç –æ—Ç due_dt –∫ due_dt + (due_dt - start_dt).\n",
    "    –ù–µ –≤—ã—Ö–æ–¥–∏—Ç –∑–∞ 1.0.\n",
    "    \"\"\"\n",
    "    if submission_dt <= due_dt:\n",
    "        return 0.0\n",
    "    total = (due_dt - start_dt).total_seconds()\n",
    "    late  = (submission_dt - due_dt).total_seconds()\n",
    "    if total <= 0:\n",
    "        return 1.0 if late > 0 else 0.0\n",
    "    return min(1.0, max(0.0, late / total))\n",
    "\n",
    "print(f\"–û–∫–Ω–æ –ø—Ä–∏—ë–º–∞: {start_dt.isoformat()} ‚Äî {due_dt.isoformat()} (UTC)\")\n",
    "print(f\"–í—Ä–µ–º—è —Å–¥–∞—á–∏: {submission_dt.isoformat()} (UTC)\")\n",
    "\n",
    "# Init raw score holder\n",
    "raw_score = 0.0\n",
    "max_points = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09aa42e3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "09aa42e3",
    "outputId": "8e8f7a24-b8f1-49ca-a131-7ec8e0199926"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch: 2.8.0+cu126\n",
      "Torchvision: 0.23.0+cu126\n",
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "# @title 2) Environment Check\n",
    "import torch, torchvision\n",
    "print(\"Torch:\", torch.__version__)\n",
    "print(\"Torchvision:\", torchvision.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a7b6b9c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6a7b6b9c",
    "outputId": "3ccc2873-fa22-48cd-ec97-c536b337f84d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# @title 3) Setup & Utilities\n",
    "import torch, torch.nn as nn, torch.optim as optim\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "from datetime import datetime\n",
    "import time, json, math, random, os\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "NUM_WORKERS = 2\n",
    "BATCH_SIZE = # YOUR CODE HERE\n",
    "NUM_EPOCHS_BASE = # YOUR CODE HERE\n",
    "SEED = 42\n",
    "random.seed(SEED); torch.manual_seed(SEED)\n",
    "\n",
    "print(\"Device:\", DEVICE)\n",
    "\n",
    "def count_trainable_params(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, dl, criterion):\n",
    "    model.eval()\n",
    "    total, correct, loss_sum = 0, 0, 0.0\n",
    "    for x, y in dl:\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "        loss_sum += loss.item() * y.size(0)\n",
    "        pred = logits.argmax(1)\n",
    "        correct += (pred == y).sum().item()\n",
    "        total += y.size(0)\n",
    "    return loss_sum/total, correct/total\n",
    "\n",
    "def train_epoch(model, dl, optimizer, criterion, scheduler=None):\n",
    "    model.train()\n",
    "    loss_sum, total = 0.0, 0\n",
    "    for x, y in dl:\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        loss_sum += loss.item() * y.size(0)\n",
    "        total += y.size(0)\n",
    "    return loss_sum/total\n",
    "\n",
    "def run_experiment(name, model, train_dl, val_dl, optimizer, criterion, scheduler=None, epochs=NUM_EPOCHS_BASE):\n",
    "    t0 = time.time()\n",
    "    history = {'train_loss': [], 'val_loss': [], 'val_acc': []}\n",
    "    best = {'val_acc': 0.0, 'state': None}\n",
    "    for ep in range(1, epochs+1):\n",
    "        tr_loss = train_epoch(model, train_dl, optimizer, criterion, scheduler)\n",
    "        val_loss, val_acc = evaluate(model, val_dl, criterion)\n",
    "        history['train_loss'].append(tr_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        if val_acc > best['val_acc']:\n",
    "            best['val_acc'] = val_acc\n",
    "            best['state'] = {k: v.detach().cpu() for k, v in model.state_dict().items()}\n",
    "        print(f\"[{name}] Epoch {ep}/{epochs} | train_loss={tr_loss:.4f} val_loss={val_loss:.4f} val_acc={val_acc:.4f}\")\n",
    "    elapsed = time.time() - t0\n",
    "    return history, best, elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "838e23df",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "838e23df",
    "outputId": "b51567bc-084b-4ad1-890d-3f2cfc08e939"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 170M/170M [01:08<00:00, 2.49MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: 10 | Train size: 50000 | Val size: 10000\n"
     ]
    }
   ],
   "source": [
    "# @title 4) Data (CIFAR10 or ImageFolder)\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "DATASET = \"CIFAR10\"  # @param [\"CIFAR10\", \"IMAGEFOLDER\"]\n",
    "train_tfms = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.7, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "val_tfms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "if DATASET == \"CIFAR10\":\n",
    "    train_ds = datasets.CIFAR10(root='./data', train=True, download=True, transform=train_tfms)\n",
    "    val_ds   = datasets.CIFAR10(root='./data', train=False, download=True, transform=val_tfms)\n",
    "    NUM_CLASSES = 10\n",
    "else:\n",
    "    # Put your data into data/train and data/val with class subfolders\n",
    "    train_ds = datasets.ImageFolder('data/train', transform=train_tfms)\n",
    "    val_ds   = datasets.ImageFolder('data/val', transform=val_tfms)\n",
    "    NUM_CLASSES = len(train_ds.classes)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "val_dl   = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "len_train, len_val = len(train_ds), len(val_ds)\n",
    "print(\"Classes:\", NUM_CLASSES, \"| Train size:\", len_train, \"| Val size:\", len_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f79d45",
   "metadata": {
    "id": "a8f79d45"
   },
   "source": [
    "## 5) Task 1 ‚Äî **Baseline from Scratch** (max 15 pts)\n",
    "Train **ResNet18 without pretrained weights** or your small CNN.\n",
    "We score by validation accuracy thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aacbadbe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aacbadbe",
    "outputId": "81296dca-76ec-44ee-fe6f-c56632dedbac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[scratch] Epoch 1/3 | train_loss=1.4484 val_loss=1.1164 val_acc=0.6025\n",
      "[scratch] Epoch 2/3 | train_loss=0.9191 val_loss=0.8314 val_acc=0.7080\n",
      "[scratch] Epoch 3/3 | train_loss=0.7054 val_loss=0.6511 val_acc=0.7822\n",
      "Task1 val_acc=0.7822 ‚Üí +15 pts (raw_score=15.0)\n"
     ]
    }
   ],
   "source": [
    "# @title Run Task 1 (Scratch)\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "def build_scratch_model(num_classes=NUM_CLASSES):\n",
    "    m = models.resnet18(weights=None)\n",
    "    m.fc = nn.Linear(m.fc.in_features, num_classes)\n",
    "    return m\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scratch_model = build_scratch_model().to(DEVICE)\n",
    "opt = # YOUR CODE HERE\n",
    "hist_scratch, best_scratch, time_scratch = run_experiment(\"scratch\", scratch_model, train_dl, val_dl, opt, criterion, epochs=NUM_EPOCHS_BASE)\n",
    "scratch_acc = max(hist_scratch['val_acc'])\n",
    "\n",
    "# Scoring (thresholds for CIFAR10 quick run)\n",
    "t1 = 0\n",
    "if scratch_acc >= 0.35: t1 = 15\n",
    "elif scratch_acc >= 0.25: t1 = 10\n",
    "elif scratch_acc >= 0.15: t1 = 5\n",
    "else: t1 = 0\n",
    "\n",
    "raw_score += t1\n",
    "print(f\"Task1 val_acc={scratch_acc:.4f} ‚Üí +{t1} pts (raw_score={raw_score})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49560f02",
   "metadata": {
    "id": "49560f02"
   },
   "source": [
    "## 6) Task 2 ‚Äî **Feature Extraction** (max 30 pts)\n",
    "Freeze all convolutional layers of a pretrained ResNet18 and train only the classifier head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff2b9327",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ff2b9327",
    "outputId": "8c578023-b08d-4c72-aed6-9d7a6765e0c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 44.7M/44.7M [00:00<00:00, 223MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[feature_extract] Epoch 1/3 | train_loss=0.9338 val_loss=0.7106 val_acc=0.7571\n",
      "[feature_extract] Epoch 2/3 | train_loss=0.7291 val_loss=0.6771 val_acc=0.7653\n",
      "[feature_extract] Epoch 3/3 | train_loss=0.7016 val_loss=0.6627 val_acc=0.7722\n",
      "Task2 val_acc=0.7722 ‚Üí +30 pts (raw_score=45.0)\n"
     ]
    }
   ],
   "source": [
    "# @title Run Task 2 (Feature Extraction)\n",
    "def build_feature_extractor(num_classes=NUM_CLASSES):\n",
    "    m = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "    for p in m.parameters():\n",
    "        p.requires_grad = False\n",
    "    m.fc = nn.Linear(m.fc.in_features, num_classes)\n",
    "    return m\n",
    "\n",
    "fe_model = build_feature_extractor().to(DEVICE)\n",
    "fe_params = [p for p in fe_model.parameters() if p.requires_grad]\n",
    "opt_fe = # YOUR CODE HERE\n",
    "hist_fe, best_fe, time_fe = run_experiment(\"feature_extract\", fe_model, train_dl, val_dl, opt_fe, criterion, epochs=NUM_EPOCHS_BASE)\n",
    "fe_acc = max(hist_fe['val_acc'])\n",
    "\n",
    "# Scoring: expect higher than scratch\n",
    "t2 = 0\n",
    "if fe_acc >= 0.60: t2 = 30\n",
    "elif fe_acc >= 0.50: t2 = 22\n",
    "elif fe_acc >= 0.40: t2 = 15\n",
    "else: t2 = 5\n",
    "\n",
    "raw_score += t2\n",
    "print(f\"Task2 val_acc={fe_acc:.4f} ‚Üí +{t2} pts (raw_score={raw_score})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea225f8",
   "metadata": {
    "id": "dea225f8"
   },
   "source": [
    "## 7) Task 3 ‚Äî **Partial Fine-Tuning** (max 30 pts)\n",
    "Unfreeze `layer4` + head, use discriminative LRs and OneCycleLR; light augment already added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f6cbdca",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6f6cbdca",
    "outputId": "d16c4350-a9de-4d05-e668-e4ed85ca0eec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[partial_finetune] Epoch 1/3 | train_loss=0.8432 val_loss=0.3972 val_acc=0.8642\n",
      "[partial_finetune] Epoch 2/3 | train_loss=0.3250 val_loss=0.2891 val_acc=0.9008\n",
      "[partial_finetune] Epoch 3/3 | train_loss=0.2177 val_loss=0.2650 val_acc=0.9094\n",
      "Task3 val_acc=0.9094 ‚Üí +30 pts (raw_score=75.0)\n"
     ]
    }
   ],
   "source": [
    "# @title Run Task 3 (Partial Fine-Tuning)\n",
    "def build_partial_ft(num_classes=NUM_CLASSES):\n",
    "    m = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "    for p in m.parameters(): p.requires_grad = False\n",
    "    for p in m.layer4.parameters(): p.requires_grad = True\n",
    "    m.fc = nn.Linear(m.fc.in_features, num_classes)\n",
    "    return m\n",
    "\n",
    "pft_model = build_partial_ft().to(DEVICE)\n",
    "params = [\n",
    "    {'params': [p for n,p in pft_model.named_parameters() if p.requires_grad and not n.startswith('fc')], 'lr': 1e-4},\n",
    "    {'params': pft_model.fc.parameters(), 'lr': 1e-3},\n",
    "]\n",
    "opt_pft = # YOUR CODE HERE\n",
    "steps_per_epoch = max(1, len(train_dl))\n",
    "sched_pft = OneCycleLR(opt_pft, max_lr=[1e-4, 1e-3], epochs=NUM_EPOCHS_BASE, steps_per_epoch=steps_per_epoch)\n",
    "hist_pft, best_pft, time_pft = run_experiment(\"partial_finetune\", pft_model, train_dl, val_dl, opt_pft, criterion, scheduler=sched_pft, epochs=NUM_EPOCHS_BASE)\n",
    "pft_acc = max(hist_pft['val_acc'])\n",
    "\n",
    "t3 = 0\n",
    "if pft_acc >= 0.65: t3 = 30\n",
    "elif pft_acc >= 0.55: t3 = 22\n",
    "elif pft_acc >= 0.45: t3 = 15\n",
    "else: t3 = 5\n",
    "\n",
    "raw_score += t3\n",
    "print(f\"Task3 val_acc={pft_acc:.4f} ‚Üí +{t3} pts (raw_score={raw_score})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b4e80c",
   "metadata": {
    "id": "08b4e80c"
   },
   "source": [
    "## 8) Task 4 ‚Äî **Full Fine-Tuning** (max 15 pts)\n",
    "Unfreeze the whole model; use OneCycleLR (or cosine annealing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89aa6e9b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "89aa6e9b",
    "outputId": "85363b8a-0d8f-4c8f-f181-9e01f488b2d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[full_finetune] Epoch 1/3 | train_loss=0.5848 val_loss=0.4217 val_acc=0.8570\n",
      "[full_finetune] Epoch 2/3 | train_loss=0.2858 val_loss=0.2204 val_acc=0.9242\n",
      "[full_finetune] Epoch 3/3 | train_loss=0.1223 val_loss=0.1389 val_acc=0.9521\n",
      "Task4 val_acc=0.9521 ‚Üí +15 pts (raw_score=90.0)\n"
     ]
    }
   ],
   "source": [
    "# @title Run Task 4 (Full Fine-Tuning)\n",
    "def build_full_ft(num_classes=NUM_CLASSES):\n",
    "    m = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "    m.fc =  # YOUR CODE HERE\n",
    "    return m\n",
    "\n",
    "fft_model = build_full_ft().to(DEVICE)\n",
    "opt_fft = optim.AdamW(fft_model.parameters(), lr=5e-4, weight_decay=1e-4)\n",
    "sched_fft = OneCycleLR(opt_fft, max_lr=5e-4, epochs=NUM_EPOCHS_BASE, steps_per_epoch=max(1, len(train_dl)))\n",
    "hist_fft, best_fft, time_fft = run_experiment(\"full_finetune\", fft_model, train_dl, val_dl, opt_fft, criterion, scheduler=sched_fft, epochs=NUM_EPOCHS_BASE)\n",
    "fft_acc = max(hist_fft['val_acc'])\n",
    "\n",
    "t4 = 0\n",
    "if fft_acc >= 0.68: t4 = 15\n",
    "elif fft_acc >= 0.58: t4 = 11\n",
    "elif fft_acc >= 0.48: t4 = 7\n",
    "else: t4 = 3\n",
    "\n",
    "raw_score += t4\n",
    "print(f\"Task4 val_acc={fft_acc:.4f} ‚Üí +{t4} pts (raw_score={raw_score})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de64ca2f",
   "metadata": {
    "id": "de64ca2f"
   },
   "source": [
    "## 9) Bonus (up to +10)\n",
    "- Domain shift or Grad-CAM analysis.\n",
    "- Set `bonus_points` (0..10) below if completed and documented in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce60c66c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ce60c66c",
    "outputId": "24d523a3-dc23-4d44-afe7-53b98e556b3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_score (with optional bonus, capped at 100) ‚Üí 90.0\n"
     ]
    }
   ],
   "source": [
    "# @title Bonus (manual)\n",
    "bonus_points = 0.0  # set 0..10 after completing bonus work\n",
    "raw_score = min(100.0, raw_score + float(bonus_points))\n",
    "print(\"raw_score (with optional bonus, capped at 100) ‚Üí\", raw_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f8304eb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8f8304eb",
    "outputId": "16c5e9b7-df6e-4261-f8c6-4a16ec3c29cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"scratch_acc\": 0.7822,\n",
      "  \"feature_extract_acc\": 0.7722,\n",
      "  \"partial_ft_acc\": 0.9094,\n",
      "  \"full_ft_acc\": 0.9521,\n",
      "  \"epochs_per_task\": 3,\n",
      "  \"device\": \"cuda\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# @title 10) Summary of Runs\n",
    "summary = {\n",
    "    \"scratch_acc\": float(max(hist_scratch['val_acc'])),\n",
    "    \"feature_extract_acc\": float(max(hist_fe['val_acc'])),\n",
    "    \"partial_ft_acc\": float(max(hist_pft['val_acc'])),\n",
    "    \"full_ft_acc\": float(max(hist_fft['val_acc'])),\n",
    "    \"epochs_per_task\": int(NUM_EPOCHS_BASE),\n",
    "    \"device\": DEVICE,\n",
    "}\n",
    "print(json.dumps(summary, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b698e687",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b698e687",
    "outputId": "c059ee5a-5ee5-4f39-9711-503184cb92ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–°—ã—Ä–æ–π –±–∞–ª–ª: 90.0/100\n",
      "–®—Ç—Ä–∞—Ñ (–¥–æ–ª—è): 0.0000\n",
      "–ò—Ç–æ–≥–æ–≤—ã–π –±–∞–ª–ª –ø–æ—Å–ª–µ —à—Ç—Ä–∞—Ñ–∞: 90.00/100\n",
      "{\"name\": \"Doe John\", \"group\": \"11-111\", \"assignment\": \"HW_MISMATCH_01\", \"score\": 90.0}\n"
     ]
    }
   ],
   "source": [
    "# @title 11) Finalize & Grade (Penalty + JSON)\n",
    "import json\n",
    "\n",
    "# –ø—Ä–∏–º–µ–Ω—è–µ–º —à—Ç—Ä–∞—Ñ\n",
    "try:\n",
    "    pf = penalty_fraction(start_dt, due_dt, submission_dt)\n",
    "except NameError:\n",
    "    from datetime import timezone\n",
    "    pf = 0.0\n",
    "# ‚úÖ –ò—Ç–æ–≥–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç\n",
    "max_points=100\n",
    "final_score = max(0.0, raw_score * (1.0 - min(1.0, pf)))\n",
    "\n",
    "print(f\"–°—ã—Ä–æ–π –±–∞–ª–ª: {raw_score}/{max_points}\")\n",
    "print(f\"–®—Ç—Ä–∞—Ñ (–¥–æ–ª—è): {pf:.4f}\")\n",
    "print(f\"–ò—Ç–æ–≥–æ–≤—ã–π –±–∞–ª–ª –ø–æ—Å–ª–µ —à—Ç—Ä–∞—Ñ–∞: {final_score:.2f}/{max_points}\")\n",
    "\n",
    "# –ü–æ—Å–ª–µ–¥–Ω—è—è —Å—Ç—Ä–æ–∫–∞ ‚Äî JSON, –∫–æ—Ç–æ—Ä—ã–π —á–∏—Ç–∞–µ—Ç harness\n",
    "final = {\n",
    "    \"name\": full_name,\n",
    "    \"group\": student_group,\n",
    "    \"assignment\": assignment_id,\n",
    "    \"score\": float(final_score)\n",
    "}\n",
    "\n",
    "print(json.dumps(final, ensure_ascii=False))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
